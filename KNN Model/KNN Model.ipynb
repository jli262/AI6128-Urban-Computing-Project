{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d7cfdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "import glob\n",
    "import math\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fca55d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training/validation set\n",
    "train_set = pd.read_csv(\"mwidata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd89918f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['a8:0c:ca:03:9d:d7', '74:ee:2a:cd:eb:43', 'a8:0c:ca:83:9d:d7', ...,\n",
       "       'magnetic', 'x', 'y'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "780ecc09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(train_set)\n",
    "pd.isnull(train_set).values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a3672ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-93.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.iloc[:, 0:2524].min().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52fbde8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_P = train_set.copy()\n",
    "train_set_P.iloc[:, 0:2524] = np.where(train_set_P.iloc[:, 0:2524] < 0, \n",
    "                train_set_P.iloc[:, 0:2524] + 100, \n",
    "                train_set_P.iloc[:, 0:2524])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "013bf201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-102.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.iloc[:, 2524:2544].min().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63cc59ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_P = train_set.copy()\n",
    "train_set_P.iloc[:, 2524:2544] = np.where(train_set_P.iloc[:, 2524:2544] < 0, \n",
    "                train_set_P.iloc[:, 2524:2544] + 105, \n",
    "                train_set_P.iloc[:, 2524:2544])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fbbed8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7841"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a single label for the model to predict. FLOOR, LATITUDE, FLOOR, and \n",
    "# BUILDINGID pinpoints the exact location of a user inside a building. Stack \n",
    "# train set and test set first before assigning unique location so that \n",
    "# identical locations are assigned the same UNIQUELOCATION value.\n",
    "combined = pd.concat([train_set_P]) # stack vertically\n",
    "combined = combined.assign(UNIQUELOCATION = (combined['x'].astype(str) + '_' + combined['y'].astype(str)))\n",
    "len(combined[\"UNIQUELOCATION\"]) # 1995 unique locations\n",
    "                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d0156e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split again\n",
    "train_set_PU = combined.iloc[0:7841, :]\n",
    "val_set_U = combined.iloc[0:7841, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec56c954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a8:0c:ca:03:9d:d7                                    float64\n",
       "74:ee:2a:cd:eb:43                                    float64\n",
       "a8:0c:ca:83:9d:d7                                    float64\n",
       "04:33:89:79:fc:7c                                    float64\n",
       "12:74:9c:2b:13:8f                                    float64\n",
       "                                                      ...   \n",
       "E7FC9D3C-EF01-4B70-B280-2CF6D50FA5CA_13394_63898     float64\n",
       "magnetic                                             float64\n",
       "x                                                    float64\n",
       "y                                                    float64\n",
       "UNIQUELOCATION                                      category\n",
       "Length: 2548, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change variable types\n",
    "train_set_PU[\"UNIQUELOCATION\"] = train_set_PU[\"UNIQUELOCATION\"].astype(\"category\")\n",
    "train_set_PU.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7cfd44fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_set_PU.iloc[:, 0:2545]\n",
    "y_train = train_set_PU.iloc[:, 2545:2548]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21ce6427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a8:0c:ca:03:9d:d7                                    float64\n",
       "74:ee:2a:cd:eb:43                                    float64\n",
       "a8:0c:ca:83:9d:d7                                    float64\n",
       "04:33:89:79:fc:7c                                    float64\n",
       "12:74:9c:2b:13:8f                                    float64\n",
       "                                                      ...   \n",
       "E7FC9D3C-EF01-4B70-B280-2CF6D50FA5CA_13394_63898     float64\n",
       "magnetic                                             float64\n",
       "x                                                    float64\n",
       "y                                                    float64\n",
       "UNIQUELOCATION                                      category\n",
       "Length: 2548, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_PU = val_set_U.copy()\n",
    "test_set_PU[\"UNIQUELOCATION\"] = test_set_PU[\"UNIQUELOCATION\"].astype(\"category\")\n",
    "test_set_PU.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a5b119e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_set_PU.iloc[:, 0:2545]\n",
    "y_test = test_set_PU.iloc[:, 2545:2548]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7318d285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a reference table for looking up the \n",
    "# POSITION associated with each UNIQUELOCATION value.\n",
    "ref_table = pd.concat([y_train.iloc[:, [0,1,2]], y_test.iloc[:, [0,1,2]]])\n",
    "ref_table = ref_table.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9adff46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- save data ---#\n",
    "def save_data(dataframe, filename):\n",
    "    file_present = glob.glob(filename) # boolean, file already present?\n",
    "    if not file_present:\n",
    "        dataframe.to_csv(filename)\n",
    "    else:\n",
    "        print('WARNING: This file already exists.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bcf99a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #-- delete unneeded datasets created during preprocessing to free up memory --#\n",
    "# del train_set, train_set_P, train_set_PU, val_set_U, test_set_PU, combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3adf0e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lijia\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Using cross-validation, train best random forest model to predict \n",
    "# UNIQUELOCATION. We report the accuracy and kappa on UNIQUELOCATION predictions\n",
    "# for cross-validation and on the training set. We report location error metrics\n",
    "# on the test set.\n",
    "\n",
    "# Using cross-validation, train best k-nn model for predicting UNIQUELOCATION.\n",
    "# For cross-validation and training set performance metrics, we will simply use \n",
    "# the accuracy and kappa of predicting UNIQUELOCATION values. We will evaluate\n",
    "# the test set performance using a method defined.\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # Select model\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    classifier = KNeighborsClassifier()\n",
    "    \n",
    "    # 'parameters' can be a list of dictionaries for more specificity in \n",
    "    # hyperparamter combinations to attempt.\n",
    "    # hyperparameters: http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier\n",
    "    # for a list of hyperparameters tried, see \"tuning_knn.csv\"\n",
    "    hyperparameters = {'n_neighbors': [1],\n",
    "                       'metric': ['manhattan']}\n",
    "   \n",
    "    \n",
    "    # Apply k-fold cross-validation with grid search\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.metrics import cohen_kappa_score\n",
    "    from sklearn.metrics import make_scorer\n",
    "    \n",
    "    scoring = {'accuracy': 'accuracy',\n",
    "               'kappa': make_scorer(cohen_kappa_score)}\n",
    "    \n",
    "    grid = GridSearchCV(estimator = classifier,\n",
    "                        param_grid = hyperparameters,\n",
    "                        scoring = scoring,\n",
    "                        cv = 2,\n",
    "                        refit = 'accuracy', # what best model is based on, and specifies that the best model will be refitted on the whole training set\n",
    "                        return_train_score = True,\n",
    "                        n_jobs = -1) # parallel processing\n",
    "    \n",
    "    tic = time.time()\n",
    "    grid_result = grid.fit(X_train, y_train.iloc[:, 2].squeeze()) # squeeze() makes sure y_train is a Series, as recommended now and required in upcoming sklearn versions.\n",
    "    toc = time.time()\n",
    "    run_time = (toc - tic)/60\n",
    "    import winsound; winsound.Beep(frequency = 1500, duration = 2000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33910768",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- cross validation metrics and training set metrics (average of folds) ----#\n",
    "cv_results_ = pd.DataFrame.from_dict(grid_result.cv_results_) \n",
    "cv_results_.insert(loc = 0, column = 'Model', \n",
    "                   value = ['KNeighborsClassifier']*cv_results_.shape[0])\n",
    "cv_results_.insert(loc = 25, column = 'mean train - cross_val accuracy', \n",
    "                   value = cv_results_['mean_train_accuracy'] - cv_results_['mean_test_accuracy'])\n",
    "cv_results_.insert(loc = 26, column = 'mean train - cross_val kappa', \n",
    "                   value = cv_results_['mean_train_kappa'] - cv_results_['mean_test_kappa'])\n",
    "with open('tuning_knn.csv', 'a') as f:\n",
    "    cv_results_.to_csv(f, header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c09e4b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metric': 'manhattan', 'n_neighbors': 1}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.best_estimator_\n",
    "grid_result.best_score_\n",
    "grid_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44fd3880",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- save best model ---#\n",
    "\n",
    "def save_model(model, model_name):\n",
    "    model_name_present = glob.glob(model_name) # boolean, same model name already present?\n",
    "    if not model_name_present:\n",
    "        pickle.dump(grid_result, open(model_name, 'wb'))\n",
    "    else:\n",
    "        print('WARNING: This file already exists.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4509d2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: This file already exists.\n"
     ]
    }
   ],
   "source": [
    "save_model(grid_result, 'KNeighborsClassifier_model.sav')\n",
    "grid_result = pickle.load(open('KNeighborsClassifier_model.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c476ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lijia\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.797474811886239"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = grid_result.predict(X_test)\n",
    "np.mean(y_pred == y_test.iloc[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d2f0463",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pos = y_test.iloc[:, 0:2].values \n",
    "\n",
    "dict_loc = {}\n",
    "m_total = ref_table.shape[0]\n",
    "for i in range(m_total):\n",
    "    key = ref_table.iloc[i]['UNIQUELOCATION']\n",
    "    value = ref_table.iloc[i, 0:4].values\n",
    "    dict_loc[key] = value\n",
    "\n",
    "y_pred_pos = np.asarray([dict_loc[i] for i in y_pred])[:, 0:2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6fff8204",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean(y_test_pos, y_pred_pos):\n",
    "    \"\"\"\n",
    "    Returns the prediction errors based on euclidean distances for each test \n",
    "    example. The prediction error for each test set example is the euclidean \n",
    "    distance between the test set's position (ground truth) and the predicted \n",
    "    position. A \"position\" is a pair of LONGITUDE and LATITUDE values, \n",
    "    e.g. -7515.92, 4.86489e+06.\n",
    "    \n",
    "    Arguments:\n",
    "    y_test_pos -- test set positions represented by numpy array of shape \n",
    "                  (m_test, 2)\n",
    "    y_pred_pos -- predicted test set position represented by numpy array of shape\n",
    "                  (m_test, 2)\n",
    "    \n",
    "    Returns:\n",
    "    D_error -- prediction errors between test set positions and predicted test \n",
    "               set positions represented by numpy array of shape (m_train, 1)\n",
    "    \"\"\"\n",
    "    m_test = y_test_pos.shape[0]\n",
    "    D_error = np.sum((y_test_pos - y_pred_pos)**2, axis = 1)**0.5\n",
    "    \n",
    "    return D_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9f503c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "D_error = euclidean(y_test_pos, y_pred_pos) # position errors for each test set example, in order as they appear \n",
    "sorted_D_error = sorted(D_error)\n",
    "\n",
    "m_test = y_test.shape[0]\n",
    "mean_error = np.mean(D_error) # meters\n",
    "percentile_25th = sorted_D_error[math.ceil(m_test*0.25) - 1] # -1 since 0-indexed. meters\n",
    "percentile_50th = sorted_D_error[math.ceil(m_test*0.50) - 1] # meters\n",
    "percentile_75th = sorted_D_error[math.ceil(m_test*0.75) - 1] # meters\n",
    "percentile_95th = sorted_D_error[math.ceil(m_test*0.95) - 1] # meters\n",
    "percentile_100th = sorted_D_error[math.ceil(m_test*1.00) - 1] # meters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10f27c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.091118828192188\n"
     ]
    }
   ],
   "source": [
    "print(mean_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dbdd9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
